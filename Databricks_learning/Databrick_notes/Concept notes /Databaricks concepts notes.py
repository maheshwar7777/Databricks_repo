# Databricks notebook source
"""
Databricks concerpts : (Check below concept definition in chat gpt or google )

1-> Pyspark
2-> spark sql  
3-> Delta tables
4-> Unity catalog (Metastore, catalog, external location , storage credential, creating (catalog, schema, tables and function)  ,data lineage, Delta sharing (to non databrick users), compute(types), creating (groups and manage), Masking, row level security, db connection (like sql server ...), Service principle & grant access)
        Service principle : Suppose when a user create jobs and workflow under as id and after few month he separated from organization, then the workfolw and job will not work, so we need to registor app in azure and create service principle and grant access to workspace, calatog ,location , schema, table and everything.

5-> Delta live tables
6-> Workflow and job schedule
7-> Databricks uility (DBFS, Widgets and notebook)
8-> Code checkin (Git hub or Git repo) 
9-> Spark optimization



"""
