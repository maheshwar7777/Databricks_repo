# Databricks notebook source
# MAGIC %md
# MAGIC
# MAGIC ### gOOGLE DOCS
# MAGIC https://docs.google.com/document/d/1-3zbUzMCKxsKjsbwExqr2VoQBu8uX9qQ/edit?usp=sharing&ouid=116457562843302399380&rtpof=true&sd=true
# MAGIC
# MAGIC
# MAGIC # Spark concept link :
# MAGIC https://www.javatpoint.com/apache-spark-introduction
# MAGIC
# MAGIC
# MAGIC #Apache Spark Tutorial
# MAGIC Apache Spark tutorial provides basic and advanced concepts of Spark. Our Spark tutorial is designed for beginners and professionals.
# MAGIC
# MAGIC Spark is a unified analytics engine for large-scale data processing including built-in modules for SQL, streaming, machine learning and graph processing.
# MAGIC
# MAGIC Our Spark tutorial includes all topics of Apache Spark with Spark introduction, Spark Installation, Spark Architecture, Spark Components, RDD, Spark real time examples and so on.
# MAGIC
# MAGIC ##What is Spark?
# MAGIC Apache Spark is an open-source cluster computing framework. Its primary purpose is to handle the real-time generated data.
# MAGIC
# MAGIC Spark was built on the top of the Hadoop MapReduce. It was optimized to run in memory whereas alternative approaches like Hadoop's MapReduce writes data to and from computer hard drives. So, Spark process the data much quicker than other alternatives.
# MAGIC
# MAGIC ##History of Apache Spark
# MAGIC The Spark was initiated by Matei Zaharia at UC Berkeley's AMPLab in 2009. It was open sourced in 2010 under a BSD license.
# MAGIC
# MAGIC In 2013, the project was acquired by Apache Software Foundation. In 2014, the Spark emerged as a Top-Level Apache Project.
# MAGIC
# MAGIC ## Features of Apache Spark
# MAGIC ##### Fast - 
# MAGIC It provides high performance for both batch and streaming data, using a state-of-the-art DAG scheduler, a query optimizer, and a physical execution engine.
# MAGIC ##### Easy to Use - 
# MAGIC It facilitates to write the application in Java, Scala, Python, R, and SQL. It also provides more than 80 high-level operators.
# MAGIC ##### Generality - 
# MAGIC It provides a collection of libraries including SQL and DataFrames, MLlib for machine learning, GraphX, and Spark Streaming.
# MAGIC ##### Lightweight - 
# MAGIC It is a light unified analytics engine which is used for large scale data processing.
# MAGIC ##### Runs Everywhere - 
# MAGIC It can easily run on Hadoop, Apache Mesos, Kubernetes, standalone, or in the cloud.
# MAGIC
# MAGIC #### Usage of Spark
# MAGIC ##### Data integration: 
# MAGIC The data generated by systems are not consistent enough to combine for analysis. To fetch consistent data from systems we can use processes like Extract, transform, and load (ETL). Spark is used to reduce the cost and time required for this ETL process.
# MAGIC ##### Stream processing: 
# MAGIC It is always difficult to handle the real-time generated data such as log files. Spark is capable enough to operate streams of data and refuses potentially fraudulent operations.
# MAGIC ##### Machine learning: 
# MAGIC Machine learning approaches become more feasible and increasingly accurate due to enhancement in the volume of data. As spark is capable of storing data in memory and can run repeated queries quickly, it makes it easy to work on machine learning algorithms.
# MAGIC ##### Interactive analytics: 
# MAGIC Spark is able to generate the respond rapidly. So, instead of running pre-defined queries, we can handle the data interactively.
